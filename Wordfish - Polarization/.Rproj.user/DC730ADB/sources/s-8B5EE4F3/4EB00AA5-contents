library(quanteda)
library(foreach)
library(doParallel)

# Set the number of parallel workers
num_cores <- 4
cl <- makeCluster(num_cores)
registerDoParallel(cl)

# Construct the DFM
# Create or load your Document Feature Matrix (DFM) using quanteda

# Parallelize the WordFish algorithm
wordfish_model <- foreach(i = 1:num_cores, .combine = "rbind") %dopar% {
  
  library(quanteda)
  require(quanteda.textmodels)
  
  # Subset the DFM for the current worker
  subset_dfm <- dfm[i:(i+12), ]  # Adjust the subset logic based on the number of cores
  
  # Apply WordFish to the subset DFM
  model <- textmodel_wordfish(subset_dfm)
  
  # Return the WordFish model
  return(model)
}

# Combine the WordFish models
final_wordfish_model <- reduce(wordfish_model)
summary(final_wordfish_model)

# Clean up the parallel workers
stopCluster(cl)
