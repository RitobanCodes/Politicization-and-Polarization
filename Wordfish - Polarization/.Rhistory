library(wordcloud)
# Read the text file
setwd('C:/Ritoban/IIMK/Newspaper Articles')
text <- readLines("combined.txt", warn = FALSE, encoding = 'utf-16')
# Create a Corpus object
corpus <- Corpus(VectorSource(text))
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Convert the document-term matrix to a frequency matrix
freq_matrix <- as.matrix(dtm)
# Sum the word frequencies across documents
word_freq <- colSums(freq_matrix)
# Create a wordcloud
wordcloud(names(word_freq), word_freq, random.order = FALSE)
install.packages("wordcloud2")
library(wordcloud2)
wordcloud2(data=text, size=1.6, color='random-dark')
library(wordcloud2)
install.packages('htmlwidgets')
library(wordcloud2)
install.packages("wordcloud2")
library(wordcloud2)
text
text <- paste(text," ")
text
# Read the .txt file using readChar()
text <- readChar("combined.txt", file.info("combined.txt")$size)
# Print the resulting text
print(text)
read.delim("combined.txt", header = FALSE, sep = " ", dec = ".", ...)
read.delim("combined.txt", header = FALSE, sep = " ")
?read
?read.delim
?read.delim("combined.txt", header = FALSE, sep = " ", encoding = 'utf-16')
read.delim("combined.txt", header = FALSE, sep = " ", encoding = 'utf-16')
library(ggwordcloud)
install.packages('ggwordcloud')
library(ggwordcloud)
wordcloud_df <-tidy_books %>%
anti_join(custom_stop_words) %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = T) %>%
top_n(200)
wordcloud_df %>%
ggplot() +
geom_text_wordcloud_area(aes(label = word, size = n)) +
scale_size_area(max_size = 15)
library(ggwordcloud)
wordcloud_df <-tidy_books %>%
anti_join(custom_stop_words) %>%
inner_join(get_sentiments("bing")) %>%
count(sentiment, word, sort = T) %>%
top_n(200)
setwd('C:/Ritoban/IIMK/Newspaper Articles')
install.packages("gutenbergr")
library(gutenbergr)
mill_all <- gutenberg_metadata %>%
filter(author = "Mill, John Stuart")
install.packages("magrittr")
library(magrittr)
install.packages("magrittr")
setwd('C:/Ritoban/IIMK/Newspaper Articles')
mill_all <- gutenberg_metadata %>%
filter(author = "Mill, John Stuart")
library(magrittr)
mill_all <- gutenberg_metadata %>%
filter(author = "Mill, John Stuart")
memory.limit()
memory.size()
seq(1,1)
months <- paste0('m',seq(1,1))
months
#rm(list=ls())
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,1))
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
#Organize wordfish results----
se <- list(summary(wordfish_results)$estimated.document.positions['se'])
positions <- data.frame(position = wordfish_results$theta,se = se)
monthly_wordfish[[month]] <- positions
}
end_time <- Sys.time()
print("Time Taken:")
(end_time-start_time)/60
monthly_wordfish
rm(list=ls())
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,1))
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
#Organize wordfish results----
se <- list(summary(wordfish_results)$estimated.document.positions['se'])
positions <- data.frame(position = wordfish_results$theta,se = se)
monthly_wordfish[[month]] <- positions
}
end_time <- Sys.time()
print("Time Taken:")
(end_time-start_time)/60
rm(list=ls())
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,26))
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
#Organize wordfish results----
se <- list(summary(wordfish_results)$estimated.document.positions['se'])
positions <- data.frame(position = wordfish_results$theta,se = se)
monthly_wordfish[[month]] <- positions
}
end_time <- Sys.time()
print("Time Taken:")
(end_time-start_time)/60
end_time-start_time
dim(monthly_wordfish)
monthly_wordfish[['m1']]
for(month in months){
write.csv(monthly_wordfish[[month]],paste0(source,'/Monthly Wordfish/All - ',month,'.csv'))
}
rm(list=ls())
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
#-------------------------------------------------------------------------------
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,26))
#-------------------------------------------------------------------------------
#
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
textplot_scale1d(tmod_wf, margin = "features")
#Organize wordfish results----
#se <- list(summary(wordfish_results)$estimated.document.positions['se'])
#positions <- data.frame(position = wordfish_results$theta,se = se)
#monthly_wordfish[[month]] <- positions
}
rm(list=ls())
require(quanteda.textplots)
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
#-------------------------------------------------------------------------------
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,26))
#-------------------------------------------------------------------------------
#
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
textplot_scale1d(tmod_wf, margin = "features")
plt.title(month)
#Organize wordfish results----
#se <- list(summary(wordfish_results)$estimated.document.positions['se'])
#positions <- data.frame(position = wordfish_results$theta,se = se)
#monthly_wordfish[[month]] <- positions
}
rm(list=ls())
require(quanteda.textplots)
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
#-------------------------------------------------------------------------------
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,26))
#-------------------------------------------------------------------------------
#
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
dfm <- dfm_trim(dfm, min_termfreq = 20, min_docfreq = 5)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
textplot_scale1d(tmod_wf, margin = "features")
plt.title(month)
#Organize wordfish results----
se <- list(summary(wordfish_results)$estimated.document.positions['se'])
positions <- data.frame(position = wordfish_results$theta,se = se)
monthly_wordfish[[month]] <- positions
}
rm(list=ls())
require(quanteda.textplots)
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
#-------------------------------------------------------------------------------
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,26))
#-------------------------------------------------------------------------------
#
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
dfm <- dfm_trim(dfm, min_termfreq = 20, min_docfreq = 5)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
#textplot_scale1d(wordfish_results, margin = "features")
plt.title(month)
#Organize wordfish results----
se <- list(summary(wordfish_results)$estimated.document.positions['se'])
positions <- data.frame(position = wordfish_results$theta,se = se)
monthly_wordfish[[month]] <- positions
}
rm(list=ls())
require(quanteda.textplots)
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
#-------------------------------------------------------------------------------
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,26))
#-------------------------------------------------------------------------------
#
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
dfm <- dfm_trim(dfm, min_termfreq = 20, min_docfreq = 5)
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
#textplot_scale1d(wordfish_results, margin = "features")
#plt.title(month)
#Organize wordfish results----
se <- list(summary(wordfish_results)$estimated.document.positions['se'])
positions <- data.frame(position = wordfish_results$theta,se = se)
monthly_wordfish[[month]] <- positions
}
end_time <- Sys.time()
print("Time Taken:")
(end_time-start_time)/60
for(month in months){
write.csv(monthly_wordfish[[month]],paste0(source,'/Monthly Wordfish/All - ',month,'.csv'))
}
(end_time-start_time)
rm(list=ls())
require(quanteda.textplots)
library(quanteda)
require(quanteda.textmodels)
start_time <- Sys.time()
read_text <- function(file_path) {
text <- readLines(file_path)
return(text)
}
read_all <- function(source){
files <- list.files(source)
prepped_text <- list()
i <- 1
for(file in files){
prepped_text[i] <- read_text(paste0(source,'/',file))
i <- i + 1
}
results <- list(texts = prepped_text,names = files)
return(results)
}
#-------------------------------------------------------------------------------
topic <- 'Covid'
source <- paste0("C:/Ritoban/IIMK/Newspaper Articles/Wordfish Data/",topic)
parties <- c('bjp','cong','regional')
months <- paste0('m',seq(1,26))
#-------------------------------------------------------------------------------
#
monthly_wordfish <- list(0)
for(month in months){
source_m <- paste0(source,'/Monthly/',month)
#Read all the documents in a list and obtain the document names
prepped_text <- read_all(source_m)$texts
names <- read_all(source_m)$names
#Create the DFM----
corpus <- corpus(c(unlist(prepped_text)))
dfm <- dfm(corpus)
if(month == 'm16'){
dfm <- dfm_trim(dfm, min_termfreq = 30, min_docfreq = 6)
}else{
dfm <- dfm_trim(dfm, min_termfreq = 20, min_docfreq = 5)
}
#Rename dfm rows
rownames(dfm) <- names
#Apply wordfish algorithm----
wordfish_results <- textmodel_wordfish(dfm, sparse = TRUE)
#textplot_scale1d(wordfish_results, margin = "features")
#plt.title(month)
#Organize wordfish results----
se <- list(summary(wordfish_results)$estimated.document.positions['se'])
positions <- data.frame(position = wordfish_results$theta,se = se)
monthly_wordfish[[month]] <- positions
}
end_time <- Sys.time()
print("Time Taken:")
(end_time-start_time)
for(month in months){
write.csv(monthly_wordfish[[month]],paste0(source,'/Monthly Wordfish/All - ',month,'.csv'))
}
